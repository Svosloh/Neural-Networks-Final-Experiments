import torch
import torchvision.transforms as transforms
from torchvision.datasets import CIFAR10
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F

# Generator network
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 8 * 8, 256)
        self.fc2 = nn.Linear(256, 4)  # 4 possible rotations: 0, 90, 180, 270 degrees

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = x.view(-1, 32 * 8 * 8)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

# Discriminator network
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)
        self.fc1 = nn.Linear(32 * 8 * 8, 256)
        self.fc2 = nn.Linear(256, 1)  # Binary classification: real or fake rotation

    def forward(self, x):
        x = F.relu(self.conv1(x))
        x = F.max_pool2d(x, 2)
        x = F.relu(self.conv2(x))
        x = F.max_pool2d(x, 2)
        x = x.view(-1, 32 * 8 * 8)
        x = F.relu(self.fc1(x))
        x = torch.sigmoid(self.fc2(x))  # Sigmoid activation for binary classification
        return x

# Hyperparameters
batch_size = 64
learning_rate = 0.001
num_epochs = 5

# Load CIFAR-10 dataset
transform = transforms.Compose([
    transforms.ToTensor()
])

train_dataset = CIFAR10(root='./data', train=True, download=True, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)

# Initialize generator and discriminator
generator = Generator()
discriminator = Discriminator()

# Define loss function and optimizers
criterion = nn.BCELoss()  # Binary Cross-Entropy Loss
optimizer_g = optim.Adam(generator.parameters(), lr=learning_rate)
optimizer_d = optim.Adam(discriminator.parameters(), lr=learning_rate)

# Training loop
for epoch in range(num_epochs):
    for images, _ in train_loader:
        # Train discriminator
        real_labels = torch.ones(images.size(0), 1)  # Real images are labeled as 1
        fake_labels = torch.zeros(images.size(0), 1)  # Fake images generated by generator are labeled as 0

        optimizer_d.zero_grad()

        # Train discriminator with real images
        outputs_real = discriminator(images)
        loss_real = criterion(outputs_real, real_labels)

        # Generate fake rotated images
        rotations = torch.randint(0, 4, (images.size(0),))  # Random rotations
        rotated_images = torch.stack([transforms.functional.rotate(image, float(angle)*90) for image, angle in zip(images, rotations)])
        fake_rotations = generator(rotated_images.detach())  # Detach to prevent gradients flowing back to generator
        outputs_fake = discriminator(rotated_images)

        # Train discriminator with fake images
        loss_fake = criterion(outputs_fake, fake_labels)

        # Backpropagation
        loss_d = loss_real + loss_fake
        loss_d.backward()
        optimizer_d.step()

        # Train generator
        optimizer_g.zero_grad()
        outputs = discriminator(rotated_images)
        loss_g = criterion(outputs, real_labels)  # Train generator to generate images classified as real
        loss_g.backward()
        optimizer_g.step()

    print(f"Epoch {epoch+1}/{num_epochs}, Generator Loss: {loss_g.item():.4f}, Discriminator Loss: {loss_d.item():.4f}")
